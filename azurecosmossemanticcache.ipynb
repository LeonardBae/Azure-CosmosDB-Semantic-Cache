{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소스 코드 설명\n",
    "\n",
    "이 파일은 Azure Cosmos DB의 Semantic Cache 기능을 설명하고 사용하는 Jupyter Notebook입니다. 주요 기능은 다음과 같습니다:\n",
    "- Azure Cosmos DB 연결 설정\n",
    "- 데이터베이스 및 컨테이너 생성\n",
    "- 데이터 삽입 및 쿼리\n",
    "- Semantic Cache 설정 및 사용\n",
    "\n",
    "아래에 소스 코드가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quiett20\\AppData\\Local\\Temp\\ipykernel_6400\\2273003635.py:21: UserWarning: You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb\n",
      "  mongo_client = MongoClient(CONNECTION_STRING)\n",
      "C:\\Users\\quiett20\\AppData\\Local\\Temp\\ipykernel_6400\\2273003635.py:60: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=chatbot_prompt)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pymongo\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from langchain_community.cache import AzureCosmosDBSemanticCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.vectorstores.azure_cosmos_db import (\n",
    "    CosmosDBSimilarityType,\n",
    "    CosmosDBVectorSearchType,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Azure Cosmos DB 및 Azure OpenAI 연결 설정\n",
    "NAMESPACE = os.getenv('DB_NAMESPACE')\n",
    "CONNECTION_STRING = (os.getenv('DB_CONNECTION_STRING'))\n",
    "DB_NAME, COLLECTION_NAME = NAMESPACE.split(\".\")\n",
    "API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "CHAT_MODEL_DEPLOY_NAME = os.getenv('AZURE_OPENAI_CHAT_MODEL_DEPLOY_NAME')\n",
    "EMBEDDINGS_MODEL_DEPLOY_NAME = os.getenv('AZURE_OPENAI_EMBEDDINGS_MODEL_DEPLOY_NAME')\n",
    "\n",
    "# Cosmos DB를 위한 MongoDB 클라이언트 초기화\n",
    "mongo_client = MongoClient(CONNECTION_STRING)\n",
    "\n",
    "# 차원 설정 (임베딩 모델에 맞게 설정)\n",
    "DIMENSIONS = 1536  # 예시 값, 모델에 따라 조정 필요\n",
    "\n",
    "def init_llm_chain():\n",
    "    # 기존 캐시가 있으면 삭제\n",
    "    mongo_client[DB_NAME][COLLECTION_NAME].drop_indexes()\n",
    "    mongo_client[DB_NAME].drop_collection(COLLECTION_NAME)\n",
    "\n",
    "    # LLM 프롬프트를 위한 템플릿 정의\n",
    "    prompt_template = \"\"\"\n",
    "    당신은 질문에 답변하는 것을 매우 기뻐하는 AI 어시스턴트입니다.\n",
    "\n",
    "    질문: {question}\n",
    "    답을 모르면 모른다고 말하세요. 답을 지어내려고 하지 마세요.\n",
    "    \"\"\"\n",
    "    chatbot_prompt = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"question\", \"context\"])\n",
    "\n",
    "    # 모델 버전 0301 이상 필요\n",
    "    # Azure OpenAI에 배포된 완성 모델 지정\n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name=CHAT_MODEL_NAME,\n",
    "        model_name=\"gpt-35-turbo\",\n",
    "        api_key=API_KEY,\n",
    "        azure_endpoint=ENDPOINT,\n",
    "        api_version=\"2024-05-01-preview\",\n",
    "        cache=True,\n",
    "        n=1)\n",
    "\n",
    "    # Azure OpenAI에 배포된 임베딩 모델 지정\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=EMBEDDINGS_MODEL_NAME,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        api_key=API_KEY,\n",
    "        azure_endpoint=ENDPOINT,\n",
    "\n",
    "    # 간단한 LLM 체인 설정\n",
    "    llm_chain = LLMChain(llm=llm, prompt=chatbot_prompt)\n",
    "\n",
    "    # LLM을 위한 시맨틱 캐시 설정\n",
    "    num_lists = 1\n",
    "    similarity_algorithm = CosmosDBSimilarityType.COS\n",
    "    kind = CosmosDBVectorSearchType.VECTOR_IVF\n",
    "\n",
    "    score_threshold = 0.9\n",
    "\n",
    "    # LLM을 위한 시맨틱 캐시 설정\n",
    "    set_llm_cache(\n",
    "        AzureCosmosDBSemanticCache(\n",
    "            cosmosdb_connection_string=CONNECTION_STRING,\n",
    "            cosmosdb_client=mongo_client,\n",
    "            embedding=embeddings,\n",
    "            database_name=DB_NAME,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            num_lists=num_lists,\n",
    "            similarity=similarity_algorithm,\n",
    "            kind=kind,\n",
    "            score_threshold=score_threshold\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return llm_chain\n",
    "\n",
    "# llm 체인 초기화\n",
    "llm_chain = init_llm_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 156 ms\n",
      "Wall time: 7.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Tell me something interesting about beer making',\n",
       " 'text': 'Did you know that the ancient Egyptians were actually some of the first brewers in history? They brewed beer for religious ceremonies and daily consumption, using techniques that have been passed down through the ages. Even today, many of the fundamental steps in beer making remain the same as they were thousands of years ago.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 두 번째 실행: 질문/응답이 이제 Cosmos DB에 캐시되었으므로 검색 속도가 빨라질 것입니다.\n",
    "llm_chain.invoke(\"Tell me something interesting about beer making\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed eval>:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 450 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Tell me a joke about tomatoes and food.',\n",
       " 'text': 'Did you know that the ancient Egyptians were actually some of the first brewers in history? They brewed beer for religious ceremonies and daily consumption, using techniques that have been passed down through the ages. Even today, many of the fundamental steps in beer making remain the same as they were thousands of years ago.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# This quesiton/response is not yet cachced in Cosmos DB, so retrieval should be slower\n",
    "llm_chain(\"Tell me a joke about tomatoes and food.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
